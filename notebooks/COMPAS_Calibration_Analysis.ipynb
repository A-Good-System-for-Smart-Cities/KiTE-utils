{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623302de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# --------------- KiTE Imports ---------------\n",
    "from KiTE.metrics import ELCE2\n",
    "from KiTE.calibrate import calibrate, calibration_error\n",
    "from KiTE.calibration_models import EWF_calibration, KRR_calibration\n",
    "\n",
    "# --------------- Visualization Imports ---------------\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "plt.style.use('tableau-colorblind10')\n",
    "# sns.set()\n",
    "\n",
    "# --------------- Model Imports ---------------\n",
    "from scipy import stats\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import pairwise_distances, pairwise_kernels, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    TheilSenRegressor,\n",
    "    RANSACRegressor,\n",
    "    HuberRegressor,\n",
    "    Ridge\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40124f7e",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "* COMPAS Data can be found at [this source](https://github.com/propublica/compas-analysis/blob/master/compas.db)\n",
    "* We use Broward Data from 2013 - 2014, inclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f41d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recidivism_data(file_name = 'BROWARD_ORIGINAL.csv'):\n",
    "    df = pd.read_csv(file_name)[\n",
    "        [\n",
    "            \"sex\",\n",
    "            \"age\",\n",
    "            \"race\",\n",
    "            \"juv_fel_count\",\n",
    "            \"juv_misd_count\",\n",
    "            \"priors_count\",\n",
    "            \"c_charge_degree\",\n",
    "            \"is_recid\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df[\"c_charge_degree\"].replace([\"F\", \"M\"], [0, 1], inplace=True)\n",
    "    df[\"sex\"].replace([\"Male\", \"Female\"], [0, 1], inplace=True)\n",
    "    df[\"age\"] /= 10.0\n",
    "\n",
    "    # Get one hot encoding of columns B\n",
    "    one_hot = pd.get_dummies(df[\"race\"])\n",
    "    \n",
    "    # Drop column B as it is now encoded\n",
    "    df = df.drop(\"race\", axis=1)\n",
    "    \n",
    "    # Join the encoded df\n",
    "    df = df.join(one_hot)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de140c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>African-American</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Native American</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  juv_fel_count  juv_misd_count  priors_count  c_charge_degree  \\\n",
       "0       0  6.9              0               0             0                0   \n",
       "1       0  3.4              0               0             0                0   \n",
       "2       0  2.4              0               0             4                0   \n",
       "3       0  2.3              0               1             1                0   \n",
       "4       0  4.3              0               0             2                0   \n",
       "...   ...  ...            ...             ...           ...              ...   \n",
       "7209    0  2.3              0               0             0                0   \n",
       "7210    0  2.3              0               0             0                0   \n",
       "7211    0  5.7              0               0             0                0   \n",
       "7212    1  3.3              0               0             3                1   \n",
       "7213    1  2.3              0               0             2                0   \n",
       "\n",
       "      is_recid  African-American  Asian  Caucasian  Hispanic  Native American  \\\n",
       "0            0                 0      0          0         0                0   \n",
       "1            1                 1      0          0         0                0   \n",
       "2            1                 1      0          0         0                0   \n",
       "3            0                 1      0          0         0                0   \n",
       "4            0                 0      0          0         0                0   \n",
       "...        ...               ...    ...        ...       ...              ...   \n",
       "7209         0                 1      0          0         0                0   \n",
       "7210         0                 1      0          0         0                0   \n",
       "7211         0                 0      0          0         0                0   \n",
       "7212         0                 1      0          0         0                0   \n",
       "7213         1                 0      0          0         1                0   \n",
       "\n",
       "      Other  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  \n",
       "...     ...  \n",
       "7209      0  \n",
       "7210      0  \n",
       "7211      1  \n",
       "7212      0  \n",
       "7213      0  \n",
       "\n",
       "[7214 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_recidivism_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88565d7e",
   "metadata": {},
   "source": [
    "# Build Random Forest Classification Model\n",
    "* Split data into train-validate-test disjoint sets\n",
    "    * Train -- Used to train the Random Forest Classifier\n",
    "    * Validate -- Used to train model calibration\n",
    "    * Test -- Used to test group-wise trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dc2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(df):\n",
    "    features = [\n",
    "        \"age\",\n",
    "        \"sex\",\n",
    "        \"African-American\",\n",
    "        \"juv_fel_count\",\n",
    "        \"juv_misd_count\",\n",
    "        \"priors_count\",\n",
    "        \"c_charge_degree\",\n",
    "        \"Asian\",\n",
    "        \"Caucasian\",\n",
    "        \"Hispanic\",\n",
    "        \"Native American\",\n",
    "        \"Other\",\n",
    "    ]\n",
    "    fair_features = [\"age\", \"sex\", \"African-American\"]\n",
    "    target = \"is_recid\"\n",
    "\n",
    "    # Split data into train, validate and test data\n",
    "    train, validate, test = np.split(\n",
    "        df.sample(frac=1), [int(0.33 * len(df)), int(0.66 * len(df))]\n",
    "    )\n",
    "\n",
    "    X_train = np.array(train[features])\n",
    "    X_cv = np.array(validate[features])\n",
    "    X_test = np.array(test[features])\n",
    "\n",
    "    X_train_fair = np.array(train[fair_features])\n",
    "    X_cv_fair = np.array(validate[fair_features])\n",
    "    X_test_fair = np.array(test[fair_features])\n",
    "\n",
    "    y_train = np.array(train[target])\n",
    "    y_cv = np.array(validate[target])\n",
    "    y_test = np.array(test[target])\n",
    "\n",
    "    # Train the Random Forest model on the 1st subset of data (training set)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    prob_test = clf.predict_proba(X_test)[:, 1]\n",
    "    prob_cv = clf.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "    return X_test, X_test_fair, y_test, X_cv, X_cv_fair, y_cv, prob_test, prob_cv, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd64dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_test,\n",
    "    X_test_fair,\n",
    "    y_test,\n",
    "    X_cv,\n",
    "    X_cv_fair,\n",
    "    y_cv,\n",
    "    prob_test,\n",
    "    prob_cv,\n",
    "    clf,\n",
    ") = build_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092d8be",
   "metadata": {},
   "source": [
    "# Compare Calibration Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4103eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    X_test,\n",
    "    prob_test,\n",
    "    y_test,\n",
    "    X_cv,\n",
    "    prob_cv,\n",
    "    y_cv,\n",
    "    method,\n",
    "    ax1,\n",
    "    ax2,\n",
    "    ax3,\n",
    "    ax4,\n",
    "    ax5,\n",
    "    ax6,\n",
    "    legend=None,\n",
    "    n_bins=20,\n",
    "    prob_kernel_wdith=0.05,\n",
    "    gamma=0.5,\n",
    "    marker=\"^\",\n",
    "    markersize=14,\n",
    "    multiplier=100.0,\n",
    "    markeredgewidth=2,\n",
    "    data=False,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    import time\n",
    "\n",
    "    # ------------- RUN CALIBRATION -------------\n",
    "    prob_cal = prob_test.copy() if method == \"No calibration\" else calibrate(X_cv,prob_cv,y_cv,Xtest=X_test,prob_test=prob_test,method=method,gamma=gamma) if method == \"EWF\" or method == \"KRR\" else calibrate(X_cv,prob_cv,y_cv,Xtest=X_test,prob_test=prob_test,method=method,**kwargs)\n",
    "\n",
    "    X_test = X_test[0 <= prob_cal]\n",
    "    y_test = y_test[0 <= prob_cal]\n",
    "    prob_cal = prob_cal[0 <= prob_cal]\n",
    "    \n",
    "    X_test = X_test[1 >= prob_cal]\n",
    "    y_test = y_test[1 >= prob_cal]\n",
    "    prob_cal = prob_cal[1 >= prob_cal]\n",
    "\n",
    "\n",
    "    # ------------- MAKE CALIBRATION CURVE + CREATE SCORES -------------\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "        y_test, prob_cal, n_bins=n_bins\n",
    "    )\n",
    "    BS_score = calibration_error(y_test, prob_cal, n_bins=n_bins, method=\"BS\")\n",
    "    ece_score = calibration_error(y_test, prob_cal, n_bins=n_bins, method=\"ECE\")\n",
    "    mce_score = calibration_error(y_test, prob_cal, n_bins=n_bins, method=\"MCE\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if data:\n",
    "        ELCE2_ = ELCE2(\n",
    "            X_test,\n",
    "            y_test,\n",
    "            prob_cal,\n",
    "            prob_kernel_width=prob_kernel_wdith,\n",
    "            kernel_function=\"rbf\",\n",
    "            gamma=gamma,\n",
    "            iterations=None,\n",
    "            verbose=False,\n",
    "        )\n",
    "    else:\n",
    "        ELCE2_, _, pvalue = ELCE2(\n",
    "            X_test,\n",
    "            y_test,\n",
    "            prob_cal,\n",
    "            kernel_function=\"rbf\",\n",
    "            prob_kernel_width=prob_kernel_wdith,\n",
    "            iterations=1000,\n",
    "            verbose=True,\n",
    "            gamma=gamma,\n",
    "        )\n",
    "    print(\"--- TIME_TAKEN = %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        \n",
    "    if data:\n",
    "        return BS_score, ece_score, mce_score, ELCE2_\n",
    "\n",
    "    if pvalue > 0.49:\n",
    "        pvalue = 0.49\n",
    "    if ELCE2_ < 0.0:\n",
    "        ELCE2_ = -0.00005\n",
    "\n",
    "        \n",
    "    # ------------- GENERATE PLOT -------------    \n",
    "    ax1.plot(\n",
    "        mean_predicted_value,\n",
    "        fraction_of_positives,\n",
    "        \"%s-\" % marker,\n",
    "        markersize=markersize - 6,\n",
    "        lw=3.0,\n",
    "        label=legend,\n",
    "    )\n",
    "    ax2.plot(\n",
    "        BS_score, 1, marker, markersize=markersize, markeredgewidth=markeredgewidth\n",
    "    )\n",
    "    ax3.plot(\n",
    "        ece_score, 1, marker, markersize=markersize, markeredgewidth=markeredgewidth\n",
    "    )\n",
    "    ax4.plot(\n",
    "        mce_score, 1, marker, markersize=markersize, markeredgewidth=markeredgewidth\n",
    "    )\n",
    "    ax5.plot(ELCE2_, 1, marker, markersize=markersize, markeredgewidth=markeredgewidth)\n",
    "    ax6.plot(pvalue, 1, marker, markersize=markersize, markeredgewidth=markeredgewidth)\n",
    "\n",
    "    print(\n",
    "        legend\n",
    "        + \" \"\n",
    "        + method\n",
    "        + \" BS : %0.3f \" % BS_score\n",
    "        + \" ECE : %0.3f \" % ece_score\n",
    "        + \" MCE : %0.3f \" % mce_score\n",
    "        + \" ELCE2 : %0.3f\" % (ELCE2_)\n",
    "    )\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbaa265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model \n",
    "def predicting_recidivism_callib(df):\n",
    "    np.random.seed(1864)\n",
    "    \n",
    "    (\n",
    "        X_test,\n",
    "        X_test_fair,\n",
    "        y_test,\n",
    "        X_cv,\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_test,\n",
    "        prob_cv,\n",
    "        clf,\n",
    "    ) = build_model(df)\n",
    "\n",
    "    # kernel hyperparameter\n",
    "    gamma = 0.5  # np.median(pairwise_distances(X_test, metric='euclidean')) ** 2\n",
    "\n",
    "    # error calibration setup\n",
    "    n_bins = 20\n",
    "\n",
    "    # #############################################################################\n",
    "    # Plot calibration plots\n",
    "    methods = ['No calibration', 'platt', 'temperature_scaling', 'isotonic', 'BBQ', 'EWF', 'KRR']\n",
    "\n",
    "    l_methods = len(methods)\n",
    "    plt.figure(figsize=(l_methods * 5, 11))\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "\n",
    "        ax1 = plt.subplot2grid((9, l_methods * 1), (0, i), rowspan=4)\n",
    "        ax2 = plt.subplot2grid((9, l_methods * 1), (4, i))\n",
    "        ax3 = plt.subplot2grid((9, l_methods * 1), (5, i))\n",
    "        ax4 = plt.subplot2grid((9, l_methods * 1), (6, i))\n",
    "        ax5 = plt.subplot2grid((9, l_methods * 1), (7, i))\n",
    "        ax6 = plt.subplot2grid((9, l_methods * 1), (8, i))\n",
    "\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"reference\")\n",
    "\n",
    "        plot_metrics(X_test_fair, prob_test, y_test, X_cv_fair, prob_cv, y_cv, method, ax1, ax2, ax3, ax4, ax5, ax6,\n",
    "                     legend=\"Recidivism Pred.\", n_bins=20, prob_kernel_wdith=0.1, gamma=gamma, marker='^',\n",
    "                     markersize=17, markeredgewidth=2)\n",
    "\n",
    "        ax1.set_xlabel(\"Mean predicted value\", size=18)\n",
    "        ax1.set_ylim([0.0, 1.])\n",
    "        ax1.set_xlim([0.0, 1.])\n",
    "        ax1.set_title(method, size=20)\n",
    "        ax1.grid()\n",
    "\n",
    "        ax2.set_yticks([])\n",
    "        ax2.set_xlim([0.0, 0.5])\n",
    "        ax3.set_yticks([])\n",
    "        ax3.set_xlim([0, 0.102])\n",
    "        ax4.set_yticks([])\n",
    "        ax4.set_xlim([0, 0.4])\n",
    "        ax5.set_yticks([])\n",
    "        ax5.set_xlim([-0.0005, 0.042])\n",
    "        ax6.set_yticks([])\n",
    "        ax6.set_xlim([-0.01, 0.5])\n",
    "\n",
    "        if i == 0:\n",
    "            ax1.set_ylabel(\"Fraction of positives\", size=18)\n",
    "            ax1.legend(loc=\"upper left\", prop={'size': 13})\n",
    "            ax2.set_ylabel(\"BS\", size=18)\n",
    "            ax3.set_ylabel(\"ECE\", size=18)\n",
    "            ax4.set_ylabel(\"MCE\", size=18)\n",
    "            ax5.set_ylabel(r\"ELCE$^2_{u}$\", size=18)\n",
    "            ax6.set_ylabel(r\"p-val\", size=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./NEW_recidivism_test.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 29.73898696899414 seconds ---\n",
      "Recidivism Pred. No calibration BS : 0.262  ECE : 0.160  MCE : 0.269  ELCE2 : 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 30.369661808013916 seconds ---\n",
      "Recidivism Pred. platt BS : 0.231  ECE : 0.022  MCE : 0.037  ELCE2 : 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 29.756721019744873 seconds ---\n",
      "Recidivism Pred. temperature_scaling BS : 0.241  ECE : 0.091  MCE : 0.207  ELCE2 : 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 30.398838996887207 seconds ---\n",
      "Recidivism Pred. isotonic BS : 0.231  ECE : 0.018  MCE : 0.046  ELCE2 : 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 134/134 [00:00<00:00, 1595.85it/s]\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 29.98333716392517 seconds ---\n",
      "Recidivism Pred. BBQ BS : 0.232  ECE : 0.009  MCE : 0.027  ELCE2 : 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TIME_TAKEN = 29.137295961380005 seconds ---\n",
      "Recidivism Pred. EWF BS : 0.256  ECE : 0.149  MCE : 0.259  ELCE2 : 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n",
      "/Users/p/.virtualenvs/data_sci/lib/python3.9/site-packages/sklearn/calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicting_recidivism_callib(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3380c",
   "metadata": {},
   "source": [
    "# Plot EWF Estimated Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb46e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_recidivism():\n",
    "    np.random.seed(1864)\n",
    "    \n",
    "    (\n",
    "        X_test,\n",
    "        X_test_fair,\n",
    "        y_test,\n",
    "        X_cv,\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_test,\n",
    "        prob_cv,\n",
    "        clf,\n",
    "    ) = build_model(df)\n",
    "\n",
    "    # kernel hyperparameter\n",
    "    gamma = 0.5\n",
    "\n",
    "    # error calibration setup\n",
    "    n_bins = 20\n",
    "    kmax = 1\n",
    "    ewf_model = EWF_calibration()\n",
    "\n",
    "    # #############################################################################\n",
    "    #                             Plot calibration plots\n",
    "    # #############################################################################\n",
    "    def plot_ewf(X_cv, y_cv, prob_cv, X_test, prob_test, ax, color=\"blue\", label=None):\n",
    "        # Train a calibration method (EWF) on 2nd data subset\n",
    "        ewf_model.fit(X_cv, prob_cv, y_cv, kernel_function=\"rbf\", gamma=gamma)\n",
    "        ewf = ewf_model.predict(X_test, prob_test, mode=\"bias\")\n",
    "        \n",
    "        # Plot outcome\n",
    "        ax.plot(\n",
    "            X_test.T[0] * 10 + 0.3 * (np.random.random() - 0.5), ewf, \".\", color=color\n",
    "        )\n",
    "\n",
    "        Xfit = X_test.T[0] * 10\n",
    "        model = make_pipeline(PolynomialFeatures(3), Ridge())\n",
    "        model.fit(Xfit[:, np.newaxis], ewf)\n",
    "\n",
    "        X_plot = np.linspace(20, 70, 201)\n",
    "        y_plot = model.predict(X_plot[:, np.newaxis])\n",
    "\n",
    "        ax.plot(X_plot, y_plot, lw=5, color=color, label=label)\n",
    "        return ax\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(2 * 7, 6))\n",
    "    ax = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax.plot([20.0, 70.0], [0, 0], \"k-\", label=\"reference\")\n",
    "\n",
    "    mask = X_test_fair.T[1] == 0\n",
    "    mask *= X_test_fair.T[2] == 1\n",
    "    ax = plot_ewf(\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_cv,\n",
    "        X_test_fair[mask],\n",
    "        prob_test[mask],\n",
    "        ax,\n",
    "        color=\"#377eb8\",\n",
    "        label=\"Male\",\n",
    "    )\n",
    "\n",
    "    mask = X_test_fair.T[1] == 1\n",
    "    mask *= X_test_fair.T[2] == 1\n",
    "    ax = plot_ewf(\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_cv,\n",
    "        X_test_fair[mask],\n",
    "        prob_test[mask],\n",
    "        ax,\n",
    "        color=\"#f781bf\",\n",
    "        label=\"Female\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylim([-0.1, 0.1])\n",
    "    plt.yticks([-0.1, -0.05, 0, 0.05, 0.1], [\"-0.1\", \"-0.05\", \"0\", \"0.05\", \"0.1\"])\n",
    "    ax.set_xlim([20, 70.0])\n",
    "\n",
    "    ax.set_title(r\"African-American\", size=25, color=\"indianred\")\n",
    "    ax.set_ylabel(\"Risk Prediction Bias\", size=24)\n",
    "    ax.set_xlabel(r\"Age [years]\", size=27)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=15)\n",
    "    ax.legend(loc=\"upper right\", prop={\"size\": 17})\n",
    "\n",
    "    ax.grid()\n",
    "    ax = plt.subplot2grid((2, 2), (0, 1))\n",
    "    ax.plot([20.0, 70.0], [0, 0], \"k-\", label=\"reference\")\n",
    "\n",
    "    mask = X_test_fair.T[1] == 0\n",
    "    mask *= X_test_fair.T[2] == 0\n",
    "    ax = plot_ewf(\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_cv,\n",
    "        X_test_fair[mask],\n",
    "        prob_test[mask],\n",
    "        ax,\n",
    "        color=\"#377eb8\",\n",
    "        label=\"Male\",\n",
    "    )\n",
    "\n",
    "    mask = X_test_fair.T[1] == 1\n",
    "    mask *= X_test_fair.T[2] == 0\n",
    "    ax = plot_ewf(\n",
    "        X_cv_fair,\n",
    "        y_cv,\n",
    "        prob_cv,\n",
    "        X_test_fair[mask],\n",
    "        prob_test[mask],\n",
    "        ax,\n",
    "        color=\"#f781bf\",\n",
    "        label=\"Female\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylim([-0.1, 0.1])\n",
    "    plt.yticks([-0.1, -0.05, 0, 0.05, 0.1], 5 * [\"\"])\n",
    "    ax.set_xlim([20, 70.0])\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=15)\n",
    "    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=15)\n",
    "\n",
    "    ax.set_xlabel(r\"Age [years]\", size=27)\n",
    "    ax.set_title(r\"Non-African-American\", size=25, color=\"indianred\")\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.02)\n",
    "    plt.savefig(\"./NEW_recidivism_test_bias.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e42561",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_recidivism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f107339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
